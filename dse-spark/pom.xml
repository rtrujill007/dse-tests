<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
        xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd">

	<modelVersion>4.0.0</modelVersion>

	<parent>
			<groupId>com.esri.realtime.dse</groupId>
			<artifactId>dse-tests-parent</artifactId>
			<version>1.0.0</version>
			<relativePath>../pom.xml</relativePath>
	</parent>

	<artifactId>dse-spark</artifactId>
	<version>1.0.0</version>
	<packaging>jar</packaging>

	<name>DSE Spark Writer</name>

	<properties>
		<spark.version>2.2.0</spark.version>
		<hadoop-api.version>2.7.3</hadoop-api.version>
		<dse.version>6.0.0</dse.version>
		<st.version>RT-1.0.0.0-SNAPSHOT</st.version>
		<kafka.version>0.10.0.1</kafka.version>
		<log4j.version>2.10.0</log4j.version>
		<curator.version>2.4.0</curator.version>

		<!-- Docker Properties -->
		<oracle.jre.version>1.8.0.151</oracle.jre.version>
		<sparkenv.file.name>spark-env.sh</sparkenv.file.name>
		<sparkenv.file.finaldest.path>/opt/spark/dist/conf/${sparkenv.file.name}</sparkenv.file.finaldest.path>
		<realtime.libs.dest>/realtime-libs</realtime.libs.dest>
		<realtime.libs.classpath>${realtime.libs.dest}/*</realtime.libs.classpath>
		<docker.namespace>rtrujill007</docker.namespace>
		<base.spark.image>mesosphere/spark:2.0.0-2.2.0-1-hadoop-2.7</base.spark.image>
		<docker.repository>dse-spark</docker.repository>
		<docker.image.name>${docker.namespace}/${docker.repository}</docker.image.name>
		<log4j2.conf.file>log4j2conf.xml</log4j2.conf.file>
	</properties>

	<repositories>
		<repository>
			<id>DataStax-Repo</id>
			<url>https://datastax.artifactoryonline.com/datastax/public-repos/</url>
		</repository>
	</repositories>

	<!-- project dependencies -->
	<dependencies>
		<dependency>
			<groupId>org.scala-lang</groupId>
			<artifactId>scala-library</artifactId>
			<version>${scala.version}</version>
		</dependency>
		<dependency>
			<groupId>org.scala-lang</groupId>
			<artifactId>scala-reflect</artifactId>
			<version>${scala.version}</version>
		</dependency>
		<dependency>
			<groupId>com.datastax.dse</groupId>
			<artifactId>dse-spark-dependencies</artifactId>
			<version>${dse.version}</version>
			<exclusions>
				<exclusion>
					<groupId>org.apache.directory.api</groupId>
					<artifactId>*</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.apache.directory.api</groupId>
					<artifactId>api-asn1-api</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.apache.directory.api</groupId>
					<artifactId>api-util</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.apache.directory.api</groupId>
					<artifactId>api-ldap-client-api</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.apache.directory.api</groupId>
					<artifactId>api-ldap-net-mina</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.apache.directory.api</groupId>
					<artifactId>api-ldap-codec-core</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.apache.directory.api</groupId>
					<artifactId>api-ldap-codec-standalone</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.apache.directory.api</groupId>
					<artifactId>api-i18n</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.apache.directory.api</groupId>
					<artifactId>api-ldap-extras-codec-api</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.apache.directory.api</groupId>
					<artifactId>api-ldap-extras-aci</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.apache.directory.api</groupId>
					<artifactId>api-asn1-ber</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.apache.directory.api</groupId>
					<artifactId>api-ldap-extras-codec</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.apache.directory.api</groupId>
					<artifactId>api-ldap-model</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.slf4j</groupId>
					<artifactId>log4j-over-slf4j</artifactId>
				</exclusion>
				<exclusion>
					<groupId>com.datastax.dse</groupId>
					<artifactId>dse-core</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.apache.spark</groupId>
					<artifactId>spark-core_2.10</artifactId>
				</exclusion>
				<exclusion>
					<groupId>io.netty</groupId>
					<artifactId>netty-all</artifactId>
				</exclusion>
				<exclusion>
					<groupId>com.datastax.cassandra</groupId>
					<artifactId>cassandra-driver-core</artifactId>
				</exclusion>
			</exclusions>
		</dependency>

		<!-- Spark -->
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-core_${scala.dep.version}</artifactId>
			<version>${spark.version}</version>
		</dependency>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-streaming_${scala.dep.version}</artifactId>
			<version>${spark.version}</version>
		</dependency>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-streaming-kafka-0-10_${scala.dep.version}</artifactId>
			<version>${spark.version}</version>
		</dependency>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-sql_${scala.dep.version}</artifactId>
			<version>${spark.version}</version>
		</dependency>
		<dependency>
			<groupId>org.apache.kafka</groupId>
			<artifactId>kafka_${scala.dep.version}</artifactId>
			<version>${kafka.version}</version>
			<exclusions>
				<exclusion>
					<groupId>org.slf4j</groupId>
					<artifactId>log4j-over-slf4j</artifactId>
				</exclusion>
			</exclusions>
		</dependency>

		<!-- Logging -->
		<dependency>
			<groupId>org.slf4j</groupId>
			<artifactId>slf4j-api</artifactId>
			<version>1.7.10</version>
		</dependency>
		<dependency>
			<groupId>org.apache.logging.log4j</groupId>
			<artifactId>log4j-core</artifactId>
			<version>${log4j.version}</version>
		</dependency>
		<dependency>
			<groupId>org.apache.logging.log4j</groupId>
			<artifactId>log4j-slf4j-impl</artifactId>
			<version>${log4j.version}</version>
		</dependency>
		<dependency>
			<groupId>org.apache.logging.log4j</groupId>
			<artifactId>log4j-1.2-api</artifactId>
			<version>${log4j.version}</version>
		</dependency>
		<dependency>
			<groupId>org.slf4j</groupId>
			<artifactId>slf4j-log4j12</artifactId>
			<version>1.7.10</version>
		</dependency>

		<!-- Tests -->
		<dependency>
			<groupId>org.apache.curator</groupId>
			<artifactId>curator-test</artifactId>
			<version>${curator.version}</version>
			<scope>test</scope>
		</dependency>
		<dependency>
			<groupId>com.bizo</groupId>
			<artifactId>mighty-csv_${scala.dep.version}</artifactId>
			<version>0.2</version>
			<scope>test</scope>
		</dependency>
	</dependencies>

	<build>
		<plugins>
			<plugin>
				<groupId>org.scala-tools</groupId>
				<artifactId>maven-scala-plugin</artifactId>
				<version>2.15.2</version>
				<configuration>
					<checkMultipleScalaVersions>false</checkMultipleScalaVersions>
					<recompileMode>incremental</recompileMode>
					<jvmArgs>
						<jvmArg>-Xss1024k</jvmArg>
						<jvmArg>-Xms64m</jvmArg>
						<jvmArg>-Xmx2048m</jvmArg>
					</jvmArgs>
				</configuration>
				<executions>
					<execution>
						<id>compile</id>
						<goals>
							<goal>compile</goal>
							<goal>testCompile</goal>
						</goals>
					</execution>
					<execution>
						<phase>process-resources</phase>
						<goals>
							<goal>compile</goal>
						</goals>
					</execution>
				</executions>
			</plugin>
			<plugin>
				<groupId>org.codehaus.mojo</groupId>
				<artifactId>build-helper-maven-plugin</artifactId>
				<version>1.8</version>
				<executions>
					<execution>
						<phase>generate-sources</phase>
						<goals>
							<goal>add-source</goal>
						</goals>
						<configuration>
							<sources>
								<source>src/main/scala</source>
								<source>src/main/java</source>
							</sources>
						</configuration>
					</execution>
				</executions>
			</plugin>
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-compiler-plugin</artifactId>
				<version>3.5.1</version>
				<configuration>
					<source>1.8</source>
					<target>1.8</target>
				</configuration>
			</plugin>
			<!-- disable surefire -->
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-surefire-plugin</artifactId>
				<version>2.12.3</version>
				<configuration>
					<skipTests>true</skipTests>
				</configuration>
			</plugin>
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-source-plugin</artifactId>
				<version>3.0.1</version>
				<executions>
					<execution>
						<id>attach-sources</id>
						<goals>
							<goal>jar</goal>
						</goals>
					</execution>
				</executions>
			</plugin>

			<plugin>
				<groupId>io.fabric8</groupId>
				<artifactId>docker-maven-plugin</artifactId>
				<version>0.22.1</version>
				<configuration>
					<skip>false</skip>
					<images>
						<image>
							<alias>dse-spark</alias>
							<name>${docker.image.name}</name>
							<build>
								<from>${base.spark.image}</from>
								<assembly>
									<descriptor>assembly.xml</descriptor>
								</assembly>
								<env>
									<CLASSPATH>${realtime.libs.classpath}</CLASSPATH>
								</env>
								<runCmds>
									<runCmd>mv /maven ${realtime.libs.dest}</runCmd>
									<runCmd>echo "export SPARK_CLASSPATH=\"${realtime.libs.classpath}\"" | tee ${sparkenv.file.finaldest.path}</runCmd>
									<!--<runCmd>rm /opt/spark/dist/jars/*log4j*</runCmd>-->
								</runCmds>
							</build>
						</image>
					</images>
					<logDate>default</logDate>
					<autoPull>true</autoPull>
					<verbose>true</verbose>
				</configuration>
				<executions>
					<execution>
						<id>create-images</id>
						<phase>package</phase>
						<goals>
							<goal>build</goal>
						</goals>
					</execution>
				</executions>
			</plugin>
		</plugins>
	</build>

</project>
